{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDj5T5hej3U3gneMSnbdNg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwOPogSfAmIl",
        "outputId": "a176ae0f-41d9-4a84-aa27-398696eb3632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "print(\"torch version:\",version(\"torch\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor([\n",
        "    [0.43,0.15,0.89],#your\n",
        "    [0.55,0.87,0.66],#journey\n",
        "    [0.57,0.85,0.64],#starts\n",
        "    [0.22,0.58,0.33],#with\n",
        "    [0.77,0.25,0.10],#one\n",
        "    [0.05,0.80,0.55] #step\n",
        "])"
      ],
      "metadata": {
        "id": "IczdC1UaAx89"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Compute unnormalized attention scores\n",
        "\n",
        "attention scores between query x2 and all other input tokens"
      ],
      "metadata": {
        "id": "2dIliSNzDwzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1] #2nd input token in query\n",
        "\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i,query)\n",
        "\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLWn2D76BeLo",
        "outputId": "ac04d1f2-43eb-4321-ff5c-f0819f3429a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot product is multiplying two vectors element wise and summing resulting products\n",
        "\n"
      ],
      "metadata": {
        "id": "9gLTz5CQFU62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res =0\n",
        "for idx, element in enumerate(inputs[0]):\n",
        "  res+=inputs[0][idx] * query[idx]\n",
        "\n",
        "print(res)\n",
        "print(torch.dot(inputs[0],query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IRClythEr37",
        "outputId": "6a5fa8d3-cd92-4914-f6ab-a191ec511bd3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9544)\n",
            "tensor(0.9544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: normalize unnormalized attention scores so that they sum upto 1\n"
      ],
      "metadata": {
        "id": "XowNGravGe-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "\n",
        "print(\"Attention Weights:\",attn_weights_2_tmp)\n",
        "print(\"Sum:\",attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpsxIaNcF_zB",
        "outputId": "56604c5f-8c27-4c8b-e655-a17e33e89591"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using softmax for normalize is common and recommended"
      ],
      "metadata": {
        "id": "vP9SsJEyHcUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_naive = softmax_naive(attn_scores_2)\n",
        "print(\"Attention weights:\",attn_weights_naive)\n",
        "print(\"Sum:\",attn_weights_naive.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emljB32iHHDX",
        "outputId": "5ec16e44-bc49-42d0-9636-eb74baca8fb0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch softmax function (optimized)\n",
        "attn_weights_2 = torch.softmax(attn_scores_2,dim=0)\n",
        "print(\"attention weights:\",attn_weights_2)\n",
        "print(\"sum:\",attn_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pQa1fplJs6E",
        "outputId": "1713167e-5dca-4873-9bcf-f0dd381294df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compute context vector\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "multiplying input tokens with attention weights and sum resulting vectors\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QKMsMQJSLXeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1] #2nd input token is the query\n",
        "context_vector_2 = torch.zeros(query.shape[0])\n",
        "print(context_vector_2)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  context_vector_2 += attn_weights_2[i] * x_i\n",
        "  print(context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CryqgSgUKzWf",
        "outputId": "562f946c-eb9d-40d8-9b53-987286254bf2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0.])\n",
            "tensor([0.0596, 0.0208, 0.1233])\n",
            "tensor([0.1904, 0.2277, 0.2803])\n",
            "tensor([0.3234, 0.4260, 0.4296])\n",
            "tensor([0.3507, 0.4979, 0.4705])\n",
            "tensor([0.4340, 0.5250, 0.4813])\n",
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "computing attention weights for all input tokens"
      ],
      "metadata": {
        "id": "RbIoDWlTN9Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xarY7qa-MOya",
        "outputId": "a17dd53c-76f0-4653-8893-8873ddd5eec7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6,6)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  for j,x_j in enumerate(inputs):\n",
        "    attn_scores[i,j]=torch.dot(x_i,x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD0TuvjzPaa0",
        "outputId": "fad569af-e8c3-41ba-d54c-7ab2b2cf33c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "can achieve the same as above more efficiently using matrix multiplication"
      ],
      "metadata": {
        "id": "MSRTniCjQBlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn0W5BXbQAzS",
        "outputId": "4dc7ce87-424c-46ca-b6d1-adf39451e968"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize\n",
        "attn_weights = torch.softmax(attn_scores,dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEtWnMJLP6wL",
        "outputId": "edc756e9-39eb-4409-85c8-20d1b2c6d3ab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#values in each row sums to 1\n",
        "row2_sum = attn_weights[1].sum()\n",
        "print(row2_sum)\n",
        "print(\"all rows sum\",attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMFM-cFeQ_bm",
        "outputId": "bf585b5a-aeb4-47c6-e59a-571f6d974e40"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n",
            "all rows sum tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqjyqoqBRQaj",
        "outputId": "cb2b4a78-f853-4f03-8b2b-95779f62bc42"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing self attention with trainable weights**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FBz9TzZiSkwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* self attention mechanism used in gpt and other popular llms\n",
        "* also called scaled dot product attention\n",
        "* weights matrics updated during training\n",
        "* three training weight matrices Wq(query), Wk(key), Wv(value)\n",
        "* input and output dimensions same in gpt but here choose different"
      ],
      "metadata": {
        "id": "CVn-a9zyn_6D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhNtJmmWSQ5E"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}