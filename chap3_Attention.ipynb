{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDj5T5hej3U3gneMSnbdNg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwOPogSfAmIl",
        "outputId": "a176ae0f-41d9-4a84-aa27-398696eb3632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "print(\"torch version:\",version(\"torch\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor([\n",
        "    [0.43,0.15,0.89],#your\n",
        "    [0.55,0.87,0.66],#journey\n",
        "    [0.57,0.85,0.64],#starts\n",
        "    [0.22,0.58,0.33],#with\n",
        "    [0.77,0.25,0.10],#one\n",
        "    [0.05,0.80,0.55] #step\n",
        "])"
      ],
      "metadata": {
        "id": "IczdC1UaAx89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Compute unnormalized attention scores\n",
        "\n",
        "attention scores between query x2 and all other input tokens"
      ],
      "metadata": {
        "id": "2dIliSNzDwzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1] #2nd input token in query\n",
        "\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i,query)\n",
        "\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "lLWn2D76BeLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot product is multiplying two vectors element wise and summing resulting products\n",
        "\n"
      ],
      "metadata": {
        "id": "9gLTz5CQFU62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res =0\n",
        "for idx, element in enumerate(inputs[0]):\n",
        "  res+=inputs[0][idx] * query[idx]\n",
        "\n",
        "print(res)\n",
        "print(torch.dot(inputs[0],query))"
      ],
      "metadata": {
        "id": "_IRClythEr37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: normalize unnormalized attention scores so that they sum upto 1\n"
      ],
      "metadata": {
        "id": "XowNGravGe-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "\n",
        "print(\"Attention Weights:\",attn_weights_2_tmp)\n",
        "print(\"Sum:\",attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "id": "VpsxIaNcF_zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using softmax for normalize is common and recommended"
      ],
      "metadata": {
        "id": "vP9SsJEyHcUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_naive = softmax_naive(attn_scores_2)\n",
        "print(\"Attention weights:\",attn_weights_naive)\n",
        "print(\"Sum:\",attn_weights_naive.sum())"
      ],
      "metadata": {
        "id": "emljB32iHHDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch softmax function (optimized)\n",
        "attn_weights_2 = torch.softmax(attn_scores_2,dim=0)\n",
        "print(\"attention weights:\",attn_weights_2)\n",
        "print(\"sum:\",attn_weights_2.sum())"
      ],
      "metadata": {
        "id": "1pQa1fplJs6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compute context vector\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "multiplying input tokens with attention weights and sum resulting vectors\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QKMsMQJSLXeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1] #2nd input token is the query\n",
        "context_vector_2 = torch.zeros(query.shape[0])\n",
        "print(context_vector_2)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  context_vector_2 += attn_weights_2[i] * x_i\n",
        "  print(context_vector_2)"
      ],
      "metadata": {
        "id": "CryqgSgUKzWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "computing attention weights for all input tokens"
      ],
      "metadata": {
        "id": "RbIoDWlTN9Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xarY7qa-MOya",
        "outputId": "a17dd53c-76f0-4653-8893-8873ddd5eec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6,6)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  for j,x_j in enumerate(inputs):\n",
        "    attn_scores[i,j]=torch.dot(x_i,x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "vD0TuvjzPaa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "can achieve the same as above more efficiently using matrix multiplication"
      ],
      "metadata": {
        "id": "MSRTniCjQBlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "Hn0W5BXbQAzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize\n",
        "attn_weights = torch.softmax(attn_scores,dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "fEtWnMJLP6wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#values in each row sums to 1\n",
        "row2_sum = attn_weights[1].sum()\n",
        "print(row2_sum)\n",
        "print(\"all rows sum\",attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "id": "YMFM-cFeQ_bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "id": "MqjyqoqBRQaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing self attention with trainable weights**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FBz9TzZiSkwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* self attention mechanism used in gpt and other popular llms\n",
        "* also called scaled dot product attention\n",
        "* weights matrics updated during training\n",
        "* three training weight matrices Wq(query), Wk(key), Wv(value)\n",
        "* input and output dimensions same in gpt but here choose different"
      ],
      "metadata": {
        "id": "CVn-a9zyn_6D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhNtJmmWSQ5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}