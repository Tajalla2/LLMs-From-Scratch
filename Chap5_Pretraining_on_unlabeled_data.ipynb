{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9vaLM8guzMXZsB1S7PqHZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez61WHb0zWpN",
        "outputId": "b6980b11-770a-43ac-9dc0-8da2dfd8e8b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZlQd7jyDEM",
        "outputId": "b479a4e9-3432-40e4-9433-9668497f37da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.26.4\n",
            "tiktoken version: 0.7.0\n",
            "torch version: 2.4.0+cu121\n",
            "tensorflow version: 2.17.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\" #for openai pretrained weights\n",
        "        ]\n",
        "\n",
        "for p in pkgs:\n",
        "  print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DARKJvKz3xcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Generative text models\n"
      ],
      "metadata": {
        "id": "7qTNhSey31At"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using gpt to generate text"
      ],
      "metadata": {
        "id": "J4-v_cSu37SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "YyQlhqGIzIOL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "e2aI57MR-seW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M ={\n",
        "    \"vocab_size\" : 50257,\n",
        "    \"context_length\" : 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval(); #disable dropuout during inference"
      ],
      "metadata": {
        "id": "MvPOg6w44hKu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0) #add batch dimension\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0) #remove batch dimension\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx = text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text: \\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-1jM8PP6RU5",
        "outputId": "208e2fcb-fecf-4c04-9d8c-1402297a9475"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: \n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating text generation loss: cross-entropy and perplexity"
      ],
      "metadata": {
        "id": "iRs0J-Fn4fio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "y4C4PFuh_Wak"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input to the model > 3 tokens each> each token is 50257 dim vector > softmax for tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits,dim=-1)\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkByQs9dBZ17",
        "outputId": "ea9328c7-6b89-4111-8f30-7f69950a62a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QnMlJbADTr9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#argmax to convert probabilities to token id of highest prob score\n",
        "token_ids = torch.argmax(probas,dim=-1,keepdim=True)\n",
        "print(\"Token ids:\\n\",token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfvP2GF9CgHc",
        "outputId": "a851c63b-65a5-40ca-c771-e31cf6deb948"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token ids:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decode to find what it predicted\n",
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBWzNLSYDp8H",
        "outputId": "d75a8036-9222-4c25-a1ba-bf1438a450ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model isn't trained yet\n",
        "#how far from correct predictions\n",
        "text_idx =0\n",
        "target_probas_1 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
        "print(\"text 1:\", target_probas_1)\n",
        "\n",
        "text_idx=1\n",
        "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
        "print('text 2: ',target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POvIcQw4EGJ4",
        "outputId": "09a8e569-0c42-40d1-bdd0-8502caa8dbbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "text 2:  tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#maximize all values > bring them close to prob of 1\n",
        "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ1fnHz1Gw1s",
        "outputId": "71452a20-17d6-4706-9670-a64435877bdd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#average log prob\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(\"average log prob:\", avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzlslZz3HnUX",
        "outputId": "1dcd30ec-01c3-4d69-97fd-504a3b63326b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average log prob: tensor(-10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)\n",
        "\n",
        "#called loss\n",
        "#already implemented in pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnK582RYH9-w",
        "outputId": "0edc0097-e607-4c06-a0fb-f2d646ecefea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of logits and targets\n",
        "print(\"logits shape:\", logits.shape)\n",
        "print('target shape:', targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD8I4b-CIUyg",
        "outputId": "efc4bf44-4c23-4bb7-ee9f-287c27f70f42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: torch.Size([2, 3, 50257])\n",
            "target shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten for pytorch cross entropy\n",
        "#flatten across batch dimension\n",
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(logits_flat.shape)\n",
        "print(targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVdUb16cIrk1",
        "outputId": "8e2e33eb-bb4d-4a20-ae13-477e948b3cfa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 50257])\n",
            "torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO_GVxwSJPED",
        "outputId": "e033cef9-82dc-4dde-81c0-352c6a9f6408"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#perplexity similar to cross entropy\n",
        "#it is exponential of cross entropy loss\n",
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefDb_1ZJhzM",
        "outputId": "fee17361-c32c-4d42-ecdc-44f9fff8cf5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48725.8203)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VO4VQGn8J2Gq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculalting training and validation set losses"
      ],
      "metadata": {
        "id": "K98LIj094kTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    text_data = response.read().decode('utf-8')\n",
        "  with open(file_path,'w',encoding='utf-8') as file:\n",
        "    file.write(text_data)\n",
        "else:\n",
        "  with open(file_path,'r',encoding='utf-8') as file:\n",
        "    text_data = file.read()"
      ],
      "metadata": {
        "id": "ELYuGWoG4sK8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_data[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TTBMC6l65uP",
        "outputId": "029fe8a4-f26c-4306-9f4d-8b3745443b9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print('total charcters in text data',total_characters)\n",
        "print('total tokens in text data',total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbfvh5_H69qa",
        "outputId": "0d1ddb04-ac64-4097-e9f5-3e08f814ec2a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total charcters in text data 20479\n",
            "total tokens in text data 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divide dataset for training and validation\n",
        "#here max length is 6 but we usually max length is equal to context len of the model that is used\n",
        "#from previous chapters import create_dataloader_v1"
      ],
      "metadata": {
        "id": "4Xr0w5Xh7af3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "ktFDBdsG932M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "Y5Edibwn-ORE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sanity check\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "  print(\"Not enough tokens for the trainig loader.\"\n",
        "  \"Try to lower the `GPT_CONFIG_124M['context_length']` or\"\n",
        "  \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "  print(\"Not enough tokens for the validation loader.\"\n",
        "  \"Try to lower the `GPT_CONFIG_124M['context_length']` or\"\n",
        "  \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "68TV2UsABt6X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if data loaded correctly\n",
        "print(\"Train Loader:\")\n",
        "for x,y in train_loader:\n",
        "  print(x.shape,y.shape)\n",
        "\n",
        "print(\"Validation Loader\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n8AYLD5C-a2",
        "outputId": "6e908575-f859-4228-e51e-11e4c9ed5d5e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "Validation Loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#additional check for token sized\n",
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "  train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "  val_tokens += input_batch.numel()\n",
        "\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNWqiOmDmiN",
        "outputId": "1e978f54-2035-4f8b-fd37-ec87848682a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fun to calculate cross entropy loss of given batch\n",
        "# fun to compute loss for user specified batches\n",
        "\n",
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
        "  return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "gEMl_f_OSi-e"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "#disable gradient tracking for efficiency because not training yet\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader,model,device)\n",
        "  val_loss = calc_loss_loader(val_loader,model,device)\n",
        "\n",
        "print(\"Training loss\",train_loss)\n",
        "print(\"Validation loss\",val_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n8zgk1tV_cH",
        "outputId": "5864eca0-8f99-48db-d915-a24492b0006d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss 10.98758347829183\n",
            "Validation loss 10.98110580444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRGqico5XxNT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainig an LLM"
      ],
      "metadata": {
        "id": "p1RjUtKsY0u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,\n",
        "                       eval_freq,eval_iter,start_context,tokenizer):\n",
        "  #initialize lists to track losses and tokens seen\n",
        "  train_losses, val_losses,track_tokens_seen = [],[],[]\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  #main training loop\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train() #set model to training mode\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad()  #reset loss gradients from previous batch iteration\n",
        "      loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      loss.backward() #calculate loss gradients\n",
        "      optimizer.step() #update model weights using loss gradients\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(\n",
        "             model, train_loader, val_loader, device, eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    #print sample text after each step\n",
        "    generate_and_print_sample(\n",
        "        model,tokenizer,device,start_context\n",
        "    )\n",
        "  return train_losses,val_losses,track_tokens_seen\n",
        "\n",
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "\n",
        "  model.train()\n",
        "  return train_loss,val_loss\n",
        "\n",
        "def generate_and_print_sample(model,tokenizer,device,start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "        model=model,idx=encoded,\n",
        "        max_new_tokens=50,context_size=context_size\n",
        "    )\n",
        "    decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\",\" \"))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "0KU7fh34Y32S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train llm\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay=0.1)\n",
        "\n",
        "num_epochs =10\n",
        "train_losses,val_losses,tokens_seen = train_model_simple(\n",
        "    model,train_loader,val_loader,optimizer,device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time)/60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VonmffCnkFnp",
        "outputId": "232eef7e-7831-4e40-bd65-bba8aa8b105c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
            "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
            "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
            "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
            "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
            "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
            "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
            "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
            "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
            "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
            "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
            "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
            "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
            "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
            "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
            "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
            "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
            "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
            "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
            "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
            "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
            "Training completed in 20.57 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def plot_losses(epochs_seen,tokens_seen,train_losses,val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5,3))\n",
        "\n",
        "  #plot training and validation losses against epochs\n",
        "  ax1.plot(epochs_seen,train_losses,label=\"Training Loss\")\n",
        "  ax1.plot(epochs_seen,val_losses,linestyle='-.',label=\"Validation Loss\")\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "  #second x axis for tokens seen\n",
        "  ax2 = ax1.twiny() #share same y axis\n",
        "  ax2.plot(tokens_seen,train_losses,alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "  fig.tight_layout() #adjust layout to make room\n",
        "  plt.savefig(\"loss-plot.pdf\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
        "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
      ],
      "metadata": {
        "id": "f_z0FAVToDPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "aab9a76b-784b-4f17-c7c6-09b61488ce4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding strategies to remove randomness"
      ],
      "metadata": {
        "id": "xiQsOlYdIO3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
        "    max_new_tokens =25,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR60DFB_Gsiw",
        "outputId": "613ca96d-9730-4987-87ef-e865cd47dfd5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding strategies > temperature scaling, tok-k sampling\n",
        "#to control randomness and diversity of generated text\n"
      ],
      "metadata": {
        "id": "LzJHhhr3J2vj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "# Suppose input is \"every effort moves you\", and the LLM\n",
        "# returns the following logits for the next token:\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "\n",
        "# The next generated token is then as follows:\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYoLxfFuVuhh",
        "outputId": "65c4b3d5-96d2-46cb-feb2-3cf32c8b623b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKlvP_FcW4QV",
        "outputId": "41535e97-029d-4b9c-c8b4-356c475594fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "  torch.manual_seed(123)\n",
        "  sample = [torch.multinomial(probas,num_samples=1).item() for i in range(1_000)]\n",
        "  sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "  for i,freq in enumerate(sampled_ids):\n",
        "    print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "\n",
        "print_sampled_tokens(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owiObp4aXqdC",
        "outputId": "a3a5ffe7-5248-4849-e407-655df3a2747e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "544 x forward\n",
            "2 x inches\n",
            "1 x moves\n",
            "0 x pizza\n",
            "376 x toward\n",
            "4 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temperature scaling\n",
        "def softmax_with_temperature(logits,temperature):\n",
        "  scaled_logits = logits/temperature\n",
        "  return torch.softmax(scaled_logits,dim=0)\n",
        "\n",
        "#temperature values\n",
        "temperatures = [1,0.1,5] # Original, higher confidence, and lower confidence\n",
        "\n",
        "#calculate scaled probabilities\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits,T) for T in temperatures]"
      ],
      "metadata": {
        "id": "nN6qIjzEaeXN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(5,3))\n",
        "for i, T in enumerate(temperatures):\n",
        "  rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
        "ax.legend\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "G-R6YcWReSg1",
        "outputId": "fea77d66-7127-4976-80f5-e387d6068de7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_sampled_tokens(scaled_probas[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQYVWdRqg3PF",
        "outputId": "552447a8-5c21-4764-df32-66aa41af6e75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "992 x forward\n",
            "0 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "8 x toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The rescaled probabilities via temperature 5 are more uniformly distributed:\n",
        "print_sampled_tokens(scaled_probas[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYWFlbUEhJLb",
        "outputId": "93113e6c-f1e1-45ce-b027-9c399b589008"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153 x closer\n",
            "68 x every\n",
            "55 x effort\n",
            "223 x forward\n",
            "102 x inches\n",
            "50 x moves\n",
            "43 x pizza\n",
            "218 x toward\n",
            "88 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top k-sampling"
      ],
      "metadata": {
        "id": "KGBntdfgiH2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits,top_k)\n",
        "print('top logits:',top_logits)\n",
        "print('top positions:',top_pos)"
      ],
      "metadata": {
        "id": "0G82X5B1hn1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ceec1ed-929e-4c53-b4d2-ec760e926801"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "    condition = next_token_logits < top_logits[-1],\n",
        "    input = torch.tensor(float(\"-inf\")),\n",
        "    other = next_token_logits\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym1GbQPKi15j",
        "outputId": "22d22141-0d01-4e01-b170-67e42fd04cb4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_probas = torch.softmax(new_logits,dim=0)\n",
        "torch_probas"
      ],
      "metadata": {
        "id": "XwehxF1OjsLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37f8805-8a00-4706-e821-b6b0a67ec650"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying the text generation function"
      ],
      "metadata": {
        "id": "OgiqHUd2XFO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#new generate function based on generate_text used earlier using temp scaling and top-k sampling\n",
        "\n",
        "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:,-1,:]\n",
        "\n",
        "  #filter logits with topk sampling\n",
        "    if top_k is not None:\n",
        "      #keep only top_k values\n",
        "      top_logits, _ = torch.topk(logits,top_k)\n",
        "      min_value = top_logits[:,-1]\n",
        "      logits = torch.where(logits < min_value, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "    #apply temperature scaling\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "\n",
        "      probs = torch.softmax(logits,dim=-1)\n",
        "      idx_next = torch.multinomial(probs,num_samples=1)\n",
        "\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits,dim=-1,keepdim=True)\n",
        "\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "\n",
        "    idx = torch.cat((idx,idx_next),dim=1)\n",
        "\n",
        "  return idx\n",
        "\n"
      ],
      "metadata": {
        "id": "AbkuUkceXAiL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Output text:\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMy3KOOucbAb",
        "outputId": "efaa0256-9430-4649-f1ef-5c0efafe0df6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: Every effort moves you know began to my surprise, a little it was the\n",
            "\"Ah enough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwzwSlpFdMJ4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and saving model weights in pytorch"
      ],
      "metadata": {
        "id": "Oio1CjF8dy4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model.pth\")"
      ],
      "metadata": {
        "id": "zMvzM1Trd3VV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model weights into new gptmodel instance\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\",map_location=device,weights_only=True))\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "5foeKKFweIDj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adaptive optimizers like adam and adamW store additional parameters, save them as well\n",
        "#to continue pretrainig later\n",
        "torch.save(\n",
        "    {\n",
        "        \"model_state_dict\":model.state_dict(),\n",
        "        \"optimizer_state_dict\":optimizer.state_dict()\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "gFEba-dUfQSV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\",weights_only=True)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0005,weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "bl2JKwcRf2mY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YD4Dpv2WhKr7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "t56Hee3bhz_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#openai used tensorflow\n",
        "\n",
        "!pip install -q tensorflow tqdm"
      ],
      "metadata": {
        "id": "-guZvEuph5C4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(version('tensorflow'))\n",
        "print(version('tqdm'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-fiQmLqiFnp",
        "outputId": "da1d0e0e-3d19-49dd-8c0a-06e8b4291446"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n",
            "4.66.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Relative import from the gpt_download.py contained in this folder\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination):\n",
        "    # Send a GET request to download the file\n",
        "\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            # Get the total file size from headers, defaulting to 0 if not present\n",
        "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "            # Check if file exists and has the same size\n",
        "            if os.path.exists(destination):\n",
        "                file_size_local = os.path.getsize(destination)\n",
        "                if file_size == file_size_local:\n",
        "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                    return\n",
        "\n",
        "            # Define the block size for reading the file\n",
        "            block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "            # Initialize the progress bar with total file size\n",
        "            progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
        "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "                # Open the destination file in binary write mode\n",
        "                with open(destination, \"wb\") as file:\n",
        "                    # Read the file in chunks and write to destination\n",
        "                    while True:\n",
        "                        chunk = response.read(block_size)\n",
        "                        if not chunk:\n",
        "                            break\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))  # Update progress bar\n",
        "    except urllib.error.HTTPError:\n",
        "        s = (\n",
        "            f\"The specified URL ({url}) is incorrect, the internet connection cannot be established,\"\n",
        "            \"\\nor the requested file is temporarily unavailable.\\nPlease visit the following website\"\n",
        "            \" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273\")\n",
        "        print(s)\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "Ndu9EAhTiQY1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "settings,params = download_and_load_gpt2(model_size=\"124M\",models_dir=\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ok3HgqzjJA2",
        "outputId": "78577fc2-4c04-491c-8515-11607a5e3962"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 99.4kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 614kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 144kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:58<00:00, 8.52MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 2.57MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 399kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 385kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\",settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C99vm4JsjiRW",
        "outputId": "6a030fb3-9fb1-425e-9475-e711b675dd13"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Parameters dictionary keys: \",params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09nPrrExjq3Z",
        "outputId": "6ee0d867-422d-40dd-ae65-022b58e72428"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters dictionary keys:  dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqNn8dvWjyZP",
        "outputId": "69d2e603-2cd1-4414-a25a-09619e6c30a2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer gpt weights onto GPTModel instance\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\":768,\"n_layers\":12,\"n_heads\":12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\":1024,\"n_layers\":24,\"n_heads\":16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\":1280,\"n_layers\":36,\"n_heads\":20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\":1600,\"n_layers\":48,\"n_heads\":25},\n",
        "}\n",
        "\n",
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\":1024,\"qkv_bias\":True})\n",
        "\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "kaSfR4nwj5xr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign openai weights to corresponding weight tensors in gptmodel instance\n",
        "def assign(left,right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "l-EWFC7-nmlJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "sv0UA0L8oUv1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "nvkPM4xr0gLq",
        "outputId": "1a7fc7cd-21e4-4418-b3e0-42994ca7a9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
          ]
        }
      ]
    }
  ]
}